from typing import List, Dict, Any
from src.core.models import SemanticChunk, IRetrievalService, IVectorStore


class HybridRetrievalAdapter(IRetrievalService):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì–´ëŒ‘í„° - IRetrievalService êµ¬í˜„."""

    def __init__(self, vector_store: IVectorStore, llm_service=None):
        self.vector_store = vector_store
        self.llm_service = llm_service  # LLM ì„œë¹„ìŠ¤ (ì„ë² ë”© ìƒì„±ìš©)

    async def retrieve(self, query: str, k: int = 20) -> List[SemanticChunk]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰."""
        # 1. ì„ë² ë”© ìƒì„±
        if self.llm_service:
            try:
                embeddings = await self.llm_service.get_embeddings([query])
                query_embedding = embeddings[0]
                print(f"ğŸ”® ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(query_embedding)}ì°¨ì›")
            except Exception as e:
                print(f"âŒ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
                query_embedding = [0.1] * 1024  # ë”ë¯¸ ì„ë² ë”© (1024ì°¨ì›)
        else:
            query_embedding = [0.1] * 1024  # ë”ë¯¸ ì„ë² ë”© (1024ì°¨ì›)

        # 2. ë²¡í„° ê²€ìƒ‰
        vector_results = await self.vector_store.search(query_embedding, k)

        # 3. BM25 ê²€ìƒ‰ (ê°„ë‹¨í•œ êµ¬í˜„)
        keyword_results = await self._bm25_search(query, k)

        # 4. RRF ìœµí•©
        combined = self._reciprocal_rank_fusion(vector_results, keyword_results)

        return [item["chunk"] for item in combined[:k]]

    async def _bm25_search(self, query: str, k: int) -> List[Dict[str, Any]]:
        """BM25 ê¸°ë°˜ ê²€ìƒ‰."""
        # ì‹¤ì œ BM25 êµ¬í˜„ í•„ìš”
        return []

    def _reciprocal_rank_fusion(
        self, vector_results: List[Dict], keyword_results: List[Dict], k: int = 60
    ) -> List[Dict]:
        """RRFë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ ìœµí•©."""
        scores = {}

        for rank, item in enumerate(vector_results):
            chunk_id = item["chunk"].chunk_id
            scores[chunk_id] = scores.get(chunk_id, 0) + 1 / (k + rank + 1)

        for rank, item in enumerate(keyword_results):
            chunk_id = item["chunk"].chunk_id
            scores[chunk_id] = scores.get(chunk_id, 0) + 1 / (k + rank + 1)

        # ê²°ê³¼ ì •ë ¬ ë° ë°˜í™˜
        sorted_chunks = sorted(scores.items(), key=lambda x: x[1], reverse=True)

        chunk_map = {
            item["chunk"].chunk_id: item for item in vector_results + keyword_results
        }

        result = []
        for chunk_id, score in sorted_chunks:
            if chunk_id in chunk_map:
                result.append(chunk_map[chunk_id])

        return result
